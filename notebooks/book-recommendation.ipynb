{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aef5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c78942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/08 20:51:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"book-recs\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e113c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users_df = spark.read.csv(path=\"data/Users.csv\", header=True, inferSchema=True)\n",
    "books_df = spark.read.csv(path=\"data/Books.csv\", header=True, inferSchema=True)\n",
    "ratings_df = spark.read.csv(path=\"data/Ratings.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e93ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in users_df.columns:\n",
    "    users_df = users_df.withColumnRenamed(col, col.replace('-', '_').lower())\n",
    "    \n",
    "for col in books_df.columns:\n",
    "    books_df = books_df.withColumnRenamed(col, col.replace('-', '_').lower())\n",
    "\n",
    "for col in ratings_df.columns:\n",
    "    ratings_df = ratings_df.withColumnRenamed(col, col.replace('-', '_').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c157566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [users_df, books_df, ratings_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b327d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n",
      "Rows in DataFrame: 278859\n",
      "+-------+--------------------+----+\n",
      "|user_id|            location| age|\n",
      "+-------+--------------------+----+\n",
      "|      1|  nyc, new york, usa|null|\n",
      "|      2|stockton, califor...|18.0|\n",
      "|      3|moscow, yukon ter...|null|\n",
      "|      4|porto, v.n.gaia, ...|17.0|\n",
      "|      5|farnborough, hant...|null|\n",
      "+-------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- book_title: string (nullable = true)\n",
      " |-- book_author: string (nullable = true)\n",
      " |-- year_of_publication: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- image_url_s: string (nullable = true)\n",
      " |-- image_url_m: string (nullable = true)\n",
      " |-- image_url_l: string (nullable = true)\n",
      "\n",
      "Rows in DataFrame: 271360\n",
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      isbn|          book_title|         book_author|year_of_publication|           publisher|         image_url_s|         image_url_m|         image_url_l|\n",
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|0195153448| Classical Mythology|  Mark P. O. Morford|               2002|Oxford University...|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "|0002005018|        Clara Callan|Richard Bruce Wright|               2001|HarperFlamingo Ca...|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "|0060973129|Decision in Normandy|        Carlo D'Este|               1991|     HarperPerennial|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "|0374157065|Flu: The Story of...|    Gina Bari Kolata|               1999|Farrar Straus Giroux|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "|0393045218|The Mummies of Ur...|     E. J. W. Barber|               1999|W. W. Norton &amp...|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- book_rating: integer (nullable = true)\n",
      "\n",
      "Rows in DataFrame: 1149780\n",
      "+-------+----------+-----------+\n",
      "|user_id|      isbn|book_rating|\n",
      "+-------+----------+-----------+\n",
      "| 276725|034545104X|          0|\n",
      "| 276726|0155061224|          5|\n",
      "| 276727|0446520802|          0|\n",
      "| 276729|052165615X|          3|\n",
      "| 276729|0521795028|          6|\n",
      "+-------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    df.printSchema()\n",
    "    print(f'Rows in DataFrame: {df.count()}')\n",
    "    df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c4f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = books_df.drop('image_url_s', 'image_url_m', 'image_url_l')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984534f",
   "metadata": {},
   "source": [
    "First let's check if there are duplicate values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36807ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in users_df: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in books_df: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in ratings_df: False\n"
     ]
    }
   ],
   "source": [
    "print(f'Dupliactes in users_df: {users_df.distinct().count() != users_df.count()}')\n",
    "print(f'Dupliactes in books_df: {books_df.distinct().count() != books_df.count()}')\n",
    "print(f'Dupliactes in ratings_df: {ratings_df.distinct().count() != ratings_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f15d35d",
   "metadata": {},
   "source": [
    "Now let's count missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aabf2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|user_id|location|   age|\n",
      "+-------+--------+------+\n",
      "|      1|       0|110518|\n",
      "+-------+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "|isbn|book_title|book_author|year_of_publication|publisher|image_url_s|image_url_m|image_url_l|\n",
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "|   0|         0|          1|                  0|        2|          0|          0|          3|\n",
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+\n",
      "|user_id|isbn|book_rating|\n",
      "+-------+----+-----------+\n",
      "|      0|   0|          0|\n",
      "+-------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, count, col\n",
    "\n",
    "for df in dfs:\n",
    "    df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051490af",
   "metadata": {},
   "source": [
    "# Popularity-based recommender system users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c003def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratings_df.join(users_df, on='user_id', how='left')\n",
    "df = df.join(books_df, on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0bee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityBasedRecSys:\n",
    "    def __init__(self, n_recs=5):\n",
    "        self.n_recs = n_recs\n",
    "        self.recs = None\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.recs = df.\\\n",
    "                    groupBy('book_title', 'book_author').agg(count('book_title').alias('popularity')).\\\n",
    "                    orderBy('popularity', ascending=False)\n",
    "       \n",
    "    def predict(self):\n",
    "        return self.recs.limit(self.n_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece71dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+\n",
      "|          book_title|    book_author|popularity|\n",
      "+--------------------+---------------+----------+\n",
      "|         Wild Animus|   Rich Shapero|      2502|\n",
      "|The Lovely Bones:...|   Alice Sebold|      1295|\n",
      "|   The Da Vinci Code|      Dan Brown|       887|\n",
      "|The Nanny Diaries...|Emma McLaughlin|       828|\n",
      "|Bridget Jones's D...| Helen Fielding|       815|\n",
      "+--------------------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pop_recsys = PopularityBasedRecSys()\n",
    "pop_recsys.fit(df)\n",
    "pop_recsys.predict().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdda46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import split, element_at\n",
    "\n",
    "# users_df = users_df.withColumn('country', element_at(split(col('Location'), ','), -1))\n",
    "# users_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a91e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityByCountryRecSys:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
