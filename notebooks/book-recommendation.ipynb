{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa022c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98147e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 12:44:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"book-recs\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629e13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema = StructType([\n",
    "    StructField('user_id', IntegerType(), True),\n",
    "    StructField('location', StringType(), True), \n",
    "    StructField('age', FloatType(), True),\n",
    "    StructField('_corrupt_record', StringType(), True)\n",
    "])\n",
    "\n",
    "users_df = spark.read.csv(\n",
    "    path='data/Users.csv', \n",
    "    schema=users_schema,\n",
    "    mode='PERMISSIVE',\n",
    "    columnNameOfCorruptRecord='_corrupt_record',\n",
    "    escape='\"'\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8391fb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+--------------------+\n",
      "|user_id|  location| age|     _corrupt_record|\n",
      "+-------+----------+----+--------------------+\n",
      "|   null|  Location|null|User-ID,Location,Age|\n",
      "| 275081|cernusco s|null|  275081,\"cernusco s|\n",
      "|   null|     milan|null|    , milan, italy\",|\n",
      "+-------+----------+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "corrupt_user_records = users_df.filter(~users_df._corrupt_record.isNull())\n",
    "corrupt_user_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcaac0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corrupt records to drop: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of corrupt records to drop: {corrupt_user_records.count()}')\n",
    "users_df = users_df.filter(users_df._corrupt_record.isNull())\n",
    "users_df = users_df.drop('_corrupt_record')\n",
    "users_df.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f1fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_schema = StructType([\n",
    "    StructField('isbn', StringType(), True),\n",
    "    StructField('book_title', StringType(), True), \n",
    "    StructField('book_author', StringType(), True),\n",
    "    StructField('year_of_publication', IntegerType(), True),\n",
    "    StructField('publisher', StringType(), True),\n",
    "    StructField('image_url_s', StringType(), True),\n",
    "    StructField('image_url_m', StringType(), True),\n",
    "    StructField('image_url_l', StringType(), True),\n",
    "    StructField('_corrupt_record', StringType(), True)\n",
    "])\n",
    "\n",
    "books_df = spark.read.csv(\n",
    "    path='data/Books.csv', \n",
    "    schema=books_schema,\n",
    "    mode='PERMISSIVE',\n",
    "    columnNameOfCorruptRecord='_corrupt_record',\n",
    "    escape='\"',\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fa5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "|      isbn|          book_title|book_author|year_of_publication|           publisher|         image_url_s|         image_url_m|image_url_l|     _corrupt_record|\n",
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "|      ISBN|          Book-Title|Book-Author|               null|           Publisher|         Image-URL-S|         Image-URL-M|Image-URL-L|ISBN,Book-Title,B...|\n",
      "|078946697X|DK Readers: Creat...|       2000|               null|http://images.ama...|http://images.ama...|http://images.ama...|       null|078946697X,\"DK Re...|\n",
      "|2070426769|Peuple du ciel, s...|       2003|               null|http://images.ama...|http://images.ama...|http://images.ama...|       null|2070426769,\"Peupl...|\n",
      "|0789466953|DK Readers: Creat...|       2000|               null|http://images.ama...|http://images.ama...|http://images.ama...|       null|0789466953,\"DK Re...|\n",
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "corrupt_book_records = books_df.filter(~books_df._corrupt_record.isNull())\n",
    "corrupt_book_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5272f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corrupt records to drop: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of corrupt records to drop: {corrupt_book_records.count()}')\n",
    "books_df = books_df.filter(books_df._corrupt_record.isNull())\n",
    "books_df = books_df.drop('_corrupt_record')\n",
    "books_df.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c2a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_schema = StructType([\n",
    "    StructField('user_id', IntegerType(), True),\n",
    "    StructField('isbn', StringType(), True), \n",
    "    StructField('book_rating', IntegerType(), True),\n",
    "    StructField('_corrupt_record', StringType(), True)\n",
    "])\n",
    "\n",
    "ratings_df = spark.read.csv(\n",
    "    path='data/Ratings.csv', \n",
    "    schema=ratings_schema,\n",
    "    mode='PERMISSIVE',\n",
    "    columnNameOfCorruptRecord='_corrupt_record',\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bcd0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+--------------------+\n",
      "|user_id|isbn|book_rating|     _corrupt_record|\n",
      "+-------+----+-----------+--------------------+\n",
      "|   null|ISBN|       null|User-ID,ISBN,Book...|\n",
      "+-------+----+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "corrupt_rating_records = ratings_df.filter(~ratings_df._corrupt_record.isNull())\n",
    "corrupt_rating_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e034c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corrupt records to drop: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of corrupt records to drop: {corrupt_rating_records.count()}')\n",
    "ratings_df = ratings_df.filter(ratings_df._corrupt_record.isNull())\n",
    "ratings_df = ratings_df.drop('_corrupt_record')\n",
    "ratings_df.unpersist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42698bde",
   "metadata": {},
   "source": [
    "First let's check if there are duplicate values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55be1c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in users_df: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in books_df: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=================================================>    (183 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupliactes in ratings_df: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'Dupliactes in users_df: {users_df.distinct().count() != users_df.count()}')\n",
    "print(f'Dupliactes in books_df: {books_df.distinct().count() != books_df.count()}')\n",
    "print(f'Dupliactes in ratings_df: {ratings_df.distinct().count() != ratings_df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcf5d1",
   "metadata": {},
   "source": [
    "Now let's count missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7134e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+\n",
      "|user_id|location|   age|\n",
      "+-------+--------+------+\n",
      "|      0|       0|110761|\n",
      "+-------+--------+------+\n",
      "\n",
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "|isbn|book_title|book_author|year_of_publication|publisher|image_url_s|image_url_m|image_url_l|\n",
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "|   0|         0|          1|                  0|        2|          0|          0|          0|\n",
      "+----+----------+-----------+-------------------+---------+-----------+-----------+-----------+\n",
      "\n",
      "+-------+----+-----------+\n",
      "|user_id|isbn|book_rating|\n",
      "+-------+----+-----------+\n",
      "|      0|   0|          0|\n",
      "+-------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, count, col\n",
    "\n",
    "for df in users_df, books_df, ratings_df:\n",
    "    df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfc12626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      isbn|          book_title|book_author|year_of_publication|           publisher|         image_url_s|         image_url_m|         image_url_l|\n",
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|9627982032|The Credit Suisse...|       null|               1995|Edinburgh Financi...|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "+----------+--------------------+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.filter(books_df['book_author'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaefe1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_book_author_isbns = books_df.filter(books_df['book_author'].isNull()).select('isbn').collect()\n",
    "ratings_df.filter(ratings_df.isbn.isin([row[0] for row in no_book_author_isbns])).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4852340",
   "metadata": {},
   "source": [
    "Book with book_author missing was rated once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b52a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+-------------------+---------+--------------------+--------------------+--------------------+\n",
      "|      isbn|     book_title|    book_author|year_of_publication|publisher|         image_url_s|         image_url_m|         image_url_l|\n",
      "+----------+---------------+---------------+-------------------+---------+--------------------+--------------------+--------------------+\n",
      "|193169656X|    Tyrant Moon|Elaine Corvidae|               2002|     null|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "|1931696993|Finders Keepers|Linnea Sinclair|               2001|     null|http://images.ama...|http://images.ama...|http://images.ama...|\n",
      "+----------+---------------+---------------+-------------------+---------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_df.filter(books_df['publisher'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40aff573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_publisher_isbns = books_df.filter(books_df['publisher'].isNull()).select('isbn').collect()\n",
    "ratings_df.filter(ratings_df.isbn.isin([row[0] for row in no_publisher_isbns])).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de24d67",
   "metadata": {},
   "source": [
    "Books with publisher missing were rated a total of two times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5edb63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = books_df.na.fill('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5acc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = books_df.drop('image_url_s', 'image_url_m', 'image_url_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f212d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct isbn values in books_df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=======================================>              (147 + 1) / 200]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "print('Distinct isbn values in books_df:')\n",
    "books_df.agg(countDistinct(col(\"isbn\"))).show()\n",
    "\n",
    "print('Distinct isbn values in ratings_df:')\n",
    "ratings_df.agg(countDistinct(col(\"isbn\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c125ac",
   "metadata": {},
   "source": [
    "# Popularity-based recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ccc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratings_df.join(users_df, on='user_id', how='left')\n",
    "df = df.join(books_df, on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c563d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityBasedRecSys:\n",
    "    \n",
    "    def __init__(self, n_recs=5):\n",
    "        self.n_recs = n_recs\n",
    "        self.recs = None\n",
    "        \n",
    "    def fit(self, df):\n",
    "#         self.recs = df.\\\n",
    "#                     groupBy('isbn').agg(count('isbn').alias('popularity')).\\\n",
    "#                     orderBy('popularity', ascending=False)\n",
    "        df.createOrReplaceTempView('data')\n",
    "        self.recs = spark.sql('''SELECT COUNT(isbn) AS popularity, isbn, book_title, book_author\n",
    "                                 FROM data\n",
    "                                 GROUP BY isbn, book_title, book_author\n",
    "                                 ORDER BY COUNT(isbn) DESC''')\n",
    "       \n",
    "    def predict(self):\n",
    "        return self.recs.limit(self.n_recs)\n",
    "\n",
    "\n",
    "pop_recsys = PopularityBasedRecSys(n_recs=10)\n",
    "pop_recsys.fit(df)\n",
    "book_recs = pop_recsys.predict()\n",
    "book_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.filter(books_df.isbn == '0679781587').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71cf773",
   "metadata": {},
   "source": [
    "Since 0679781587 isbn is not present in books_df, book_title and book_author will not be present in the resulting data frame of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighestRatedPopularityBasedRecSys(PopularityBasedRecSys):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def fit(self, df):\n",
    "        df.createOrReplaceTempView('data')\n",
    "        self.recs = spark.sql('''SELECT isbn, AVG(book_rating) AS popularity, book_title, book_author\n",
    "                                 FROM data\n",
    "                                 GROUP BY isbn, book_title, book_author\n",
    "                                 ORDER BY popularity DESC''')\n",
    "        \n",
    "        \n",
    "highest_rated_pop_recsys = HighestRatedPopularityBasedRecSys()\n",
    "highest_rated_pop_recsys.fit(df)\n",
    "highest_rated_book_recs = highest_rated_pop_recsys.predict()\n",
    "highest_rated_book_recs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edb8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RatingWeightedPopularityBasedRecSys(PopularityBasedRecSys):\n",
    "    \n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#     def fit(self, df):\n",
    "#         df.createOrReplaceTempView('data')\n",
    "#         self.recs = spark.sql('''SELECT isbn, COUNT(isbn) AS num_reads, ROUND(AVG(book_rating), 2) AS book_rating,\\\n",
    "#                                         COUNT(isbn) * AVG(book_rating) AS popularity, book_title, book_author\n",
    "#                                  FROM data\n",
    "#                                  GROUP BY isbn, book_title, book_author\n",
    "#                                  ORDER BY popularity DESC''')\n",
    "\n",
    "# rating_weighted_pop_recsys = RatingWeightedPopularityBasedRecSys()\n",
    "# rating_weighted_pop_recsys.fit(df)\n",
    "# rating_weighted_book_recs = rating_weighted_pop_recsys.predict()\n",
    "# rating_weighted_book_recs.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
